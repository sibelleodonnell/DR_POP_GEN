############ Analysis of Dominican Republic Samples ##########
# All bioinformatic and downstream ANGSD analyses must be done separately for each species
# ----------------------- Demultiplexing ligation pools
# If you are downloading the .fastq files from NCBI, you can jump to the next section (downloading reads from NCBI)
# Code below is only included to demonstrate the demultiplexing and trimming performed to create the resulting .tr0 files

# Filter for PCR duplicates from separate lanes of the run prior to concatenating samples
#Create list of unique identifiers

ls -1 *.fastq | cut -d'.' -f1 > ID

for i in `cat ./ID`; do echo trim2bRAD_2barcodes_dedup_N2.pl input=$i.fastq site=\"\.{12}CGA\.{6}TGC\.{12}\|\.{12}GCA\.{6}TCG\.{12}\" adaptor=\"AGATC?\" sampleID=100 deduplicate=1 bc=[ATGC]{4} minBCcount=5000; done > ToDo

#^ paste parameters into a shell script (ex name: todo.sh)
module load perl/5.36.0

# Use parallel slurm script to submit jobs. Then look in .out file to get summary of goods vs dups for each sample and save to common text summary file
sbatch todo.sh trim2bRAD_2barcodes_dedup_N2.pl

#Then must concatenate pools from the different runs and lanes by ligation barcode
#first, create list of unique identifiers and move to top level directory

ls -1 *.tr0 | cut -d'.' -f 1 | sort | uniq > ID 

mv ID ..

#Then, rename files based on adapter - need 2 column csv file, where 1st column is pool_adap notation and 2nd is actual sample name - create this and then import - be sure to dbl check that there's no weird line endings (ex: extra spaces) before proceeding!
ls *tr0
#in spreadsheet match up sample names - note: be sure to add .tr0 to new filenames too. Save as a .csv
head MappingFile.csv | cat -vet

#note if there is weird ^M before newline - kill it with sed
sed -e "s/^M//" MappingFile.csv > mappingFileClean.csv

#Rename files using .csv 
awk -F',' '{print "mv "$1" "$2""}' mappingFileClean.csv >> mappingjob.sh


# ----------------------- downloading reads from NCBI SRA
# Bioproject: PRJNA1093451
# to get reads from NCBI SRA database, first install sra-toolkit: https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software 


#Paste the names of all sample accession numbers (ex: SRR28497447) into a .txt file and run code below
prefetch --option-file SRR_Files.txt
for S in `cat SRR_Files.txt`; do fasterq-dump $S; done

# this will generate fastq files with their NCBI SRR* names. 
# Files contain .tr0 files. 

# ------- O. faveolata Reference Genome: from Prada C, Hanna B, Budd AF, Woodley CM, Schmutz J, Grimwood J, Iglesias-Prieto R, Pandolfi JM, Levitan D, Johnson KG, Knowlton N, Kitano H, DeGiorgio M, Medina M (2016) Empty Niches after Extinctions Increase Population Sizes of Modern Corals. Curr Biol 26:3190â€“3194

https://www.ncbi.nlm.nih.gov/Traces/wgs/?val=MZGG01#contigs
ftp://ftp.ncbi.nlm.nih.gov/sra/wgs_aux/MZ/GG/MZGG01/MZGG01.1.fsa_nt.gz

# ------- P. astreoids Reference Genome: from Wong KH, Putnam HM (2022) The genome of the mustard hill coral, Porites astreoides. GigaByte 2022:gigabyte65

https://www.ncbi.nlm.nih.gov/biosample/SAMN28031657

# ------- A. agaricia denovo Reference Genome: Created by Maria Ruggeri. See paper and supplementary materials for more information. AgarRefGeno in repo. 

# ------- Symbiont reference genome: See paper's supplementary materials. 


# ----------------------- Mapping .tr0 files to reference genome
#Create a list of filenames and move everyone into subdirectories
ls *tr0 | cut -d'.' -f 1 > ID

#Paste the following into a shell script (see RefComp.sh in repo for example and module loads)
#Find adaptors.fasta file in GitHub repository
cat $NAME".tr0" | fastq_quality_filter -q 20 -p 90 > $NAME".trim" #relaxed percent of reads mapping to increase retention of reads
bbduk.sh in=$NAME".trim" ref=/path/to/adaptors.fasta k=12 stats=stats2.txt out=$NAME".clean"
GENOME_FASTA=/path/to/genome/fasta
bowtie2 --threads 16 --no-unal --score-min L,16,1 --local -L 16 -x $GENOME_FASTA -U $NAME".clean" -S $NAME"bt2.sam"

sbatch batch.sh RefComp.sh ID ClnMap

#Extract N reads cleaned from summary files for later reporting 
#for reads post quality filtering (Assuming all sample files and file directory names start with A - A* is used to cat files)
cat A*/stats2.txt | grep -A 1 'File'
# Store output in Postqualfilter_M
cat A*/stats2.txt | grep -A 1 'File' > Postqualfilter
#Percent mapping stats 
cat A*/Cln*err | grep -A 4 'unpaired;'
#To save mapping stats
find /scratch1/seodonne/DR_POP_GEN/Agar -type f -name "ClnMap*err" -exec cat {} + > /scratch1/seodonne/DR_POP_GEN/Agar/MappingStatsAgar.txt

# ----------------------- Pulling out reads mapping to symbiont genomes to quantify sym type
#back in top level directory
find /path/to/top/level/directory -type f -name "*.sam2" -exec cp {} /path/to/top/level/directory \;

### zooxType.pl custom perl script is from Manzello et al, "Role of host genetics and heat tolerant algal symbionts in sustaining populations of the endangered coral Orbicella faveolata in the Florida Keys with ocean warming", Global Change Biology 2019, 25(3):1016-1031. doi: 10.1111/gcb.14545. 
### Github link to zooxType.pl: https://github.com/z0on/ClonesAndClades_Ofav_Keys/blob/master/zooxType.pl

#Change host= to be species specific. 
# To find the host name, head either a .sam file or the genome.fasta file
#Store in shell script (ex name: zoox.sh)
zooxType.pl host="NW_018148670.1" symgenomes=20-23 > zooxCounts.txt

zooxType.pl
sbatch zoox.sh

# ----------------------- Extracting host read alignments for downstream pop gen analyses
# (rewriting sam files omitting mappings to chr20-chr23) submit as a job
for S in *bt2.sam; do
  NNAME="${S%.sam}.sam"
  echo "$NNAME"
  egrep -v "chr20|chr21|chr22|chr23" "$S" > "$NNAME"
done

#then move these back into subdirectories (submit code below as a job)
# Check if the file is a regular file (not a directory)
    if [ -f "$file" ]; then
        # Extract the first three characters of the filename
        prefix=$(echo "$file" | cut -c 1-3)

        # Check if a directory with the same name as the prefix exists
        if [ -d "$prefix" ]; then
            # Move the file to the corresponding directory
            mv "$file" "$prefix/"
        fi
    fi
done


# ----------------------- Converting .sam to .bam files prior to running ANGSD
# Submit as a batch job (ex name: samtobam.sh). Replace GENOME_FASTA with path to reference genome

module load samtools/1.14
GENOME_FASTA=/path/to/reference/genome/.fasta
samtools import $GENOME_FASTA $NAME".sam" unsorted.bam && samtools sort -o sorted.bam unsorted.bam && java -Xmx5g -jar $PICARD AddOrReplaceReadGroups INPUT=sorted.bam OUTPUT=$NAME".bam" RGID=group1 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=$NAME && samtools index $NAME".bam"

sbatch batch.sh samtobam.sh ID bams

# Move .bam and .bai files back to main directory 
find /path/to/top/directory -type f -name "*.bam" -exec cp {} /path/to/top/directory \;

mkdir bams_q20p90


mv *bam bams_q20p90
mv *bam bams_q20p90


###DONE###
# Proceed to DR_ANGSD.txt file in repo





